{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Wifi Positioning with RSSI Fingerprints\n",
    "You will get a dataset that was gathered by the Minodes team to enable wifi positioning. In this store we installed 145 of our sensors, also called **nodes**. \n",
    "\n",
    "As you walk through the store your phone searches for available wifi networks, by sending probe requests (see 802.11 standard). A part of this probe request is the received signal strength indication (**RSSI**), which has a range between 0db (very strong signal) and -100db (very weak signal). Depending on the distance of your phone to a sensor, the **RSSI** has a different value. In an ideal case one probe request would be perceived by all nodes of the store with different signal strength. In our data processing we collect all this probe requests and aggregate them, so that we have all **RSSI** values for all nodes of one probe request available:\n",
    "\n",
    "A data set might look like this:\n",
    "\n",
    "\n",
    "|  ID             | RSSI value node 1 | RSSI value node 2  | .... | RSSI value node n  | fr_zone_id |\n",
    "| -------------   |-------------      | -----              | -----| -------------------| ------- |\n",
    "| 1               |-70                | -70                | .... |  -70               | 1       |\n",
    "| 2               |-55                | -60                | .... |  -45               | 2       |\n",
    "| 2               |-60                | -60                | .... |  -45               | 2       |\n",
    "| ...             |.......            | ....               | .... | ....               | ..      |\n",
    "\n",
    "Each line of this the table is called a fingerprint, which gives us an indication about the potential location of a person.\n",
    "\n",
    "To locate a person within the store, we separate the store into zones representing compartments of a store. For each of this **zones** we collect reference data, which is stored in the file *training_set.csv* of this exercise.\n",
    "\n",
    "The goal of this task is to use machine learning techniques to predict the correct zones, based on **RSSI** fingerprints. At the end of this task you need to predict the zones of unkown **RSSI** fingerprints stored in the file *test_without_target.csv*. \n",
    "\n",
    "Since we at Minodes love to code, we have done some preparation work, so you can focus on the machine learning.\n",
    "\n",
    "In case you have any questions please contact **alexander.mueller@minodes.com**\n",
    "\n",
    "## Remarks\n",
    "\n",
    "* Please use python 3.x\n",
    "* I suggest using an anaconda python distribution https://www.continuum.io/downloads\n",
    "* The code is tested in python 3.4\n",
    "* Please use pre-existing libraries\n",
    "\n",
    "## Requirements\n",
    "The current versions of:\n",
    "* pandas \n",
    "* numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some imports and a preprocessing routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "def preprocess_x_values(x_raw_values):\n",
    "    \"\"\"\n",
    "    A simple preprocessing routine returning a feature vector for the specific fingerprint. \n",
    "    \"\"\"\n",
    "\n",
    "    v = DictVectorizer(sparse=False)\n",
    "    \n",
    "    return v.fit_transform(x_raw_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set = pd.read_csv('training_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "\n",
    "# Parse dictionary of features\n",
    "training_set['values'] =training_set['values'].apply(lambda x:  ast.literal_eval(x))\n",
    "\n",
    "# preparing x and y sets \n",
    "# x are the features of the set\n",
    "# y is the class to be predicted\n",
    "x_raw = training_set['values']\n",
    "y = training_set['fr_zone_id']\n",
    "\n",
    "# preprocess the node dictionary to get feature vectors\n",
    "x_features= preprocess_x_values(x_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63134, 137)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "       [  0., -75., -71., ...,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,   0.],\n",
       "       ..., \n",
       "       [  0.,   0.,   0., ..., -75.,   0., -78.],\n",
       "       [-54., -58., -50., ...,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "Think about how you validate your model (based on accuracy), what classifier you want to use and how in the end you want to scorce the test set.\n",
    "\n",
    "You need to add only a couple of lines of code to have a basic solution. Do this first and then iterate on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  please start here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict and unkown dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('test_without_target.csv',index_col='id')\n",
    "test_set['values'] = test_set['values'].apply(lambda x:  ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit your solution\n",
    "Please zip the complete folder with your solution and send it back to **alexander.mueller@minodes.com**. We will review it as soon as possible and will come back to you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
